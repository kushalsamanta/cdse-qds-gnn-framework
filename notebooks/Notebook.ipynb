{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e8c2324-7bbd-4850-a960-8a33bcbd6ffc",
   "metadata": {},
   "source": [
    "# Getting Started — Official **ALIGNN** Framework\n",
    "\n",
    "This notebook builds on the open‑source  \n",
    "[**Atomistic Line Graph Neural Network (ALIGNN)**](https://github.com/usnistgov/alignn)  \n",
    "by **Kamal Choudhary et al.**  \n",
    "\n",
    "ALIGNN embeds **both** the atom‑bond graph **and** its bond‑angle line‑graph,\n",
    "delivering state‑of‑the‑art accuracy for materials‑property prediction.\n",
    "\n",
    "> **Reference**  \n",
    "> *Choudhary K.* **et al.**  \n",
    "> “ALIGNN: Atomistic Line Graph Neural Network for Improved Materials Property Prediction.”  \n",
    "> *npj Computational Materials* **7**, 185 (2021).  \n",
    "> DOI: [10.1038/s41524‑021‑00650‑1](https://www.nature.com/articles/s41524-021-00650-1)\n",
    "\n",
    "---\n",
    "\n",
    "#### ALIGNN version used in this study\n",
    "\n",
    "```bash\n",
    "# choose one package manager\n",
    "pip install alignn==2024.01.01      # PyPI\n",
    "# — or —\n",
    "conda install -c conda-forge alignn=2024.01.01\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1c9c8d-aa1a-443f-a4f8-e3c1b296bcae",
   "metadata": {},
   "source": [
    "## 1 · Workflow focus — **Cd<sub>28</sub>Se<sub>17</sub>Cl<sub>22</sub>**\n",
    "\n",
    "All demonstrations below use the **Cl‑passivated quantum dot**  (Cd<sub>28</sub>Se<sub>17</sub>Cl<sub>22</sub>).  \n",
    "The *same* workflow applies to Cd<sub>28</sub>Se<sub>17</sub>(OH)<sub>22</sub>;  \n",
    "we show the band‑gap (HOMO–LUMO gap) of the Cl system for clarity.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d90cb6-25c0-42a5-bb6e-532f461e2ebe",
   "metadata": {},
   "source": [
    "## 2 · Context\n",
    "\n",
    "* **AIMD length:** 10 ps • **Timestep:** 1 fs  \n",
    "* **Geometry files:** `st1.vasp … st10001.vasp` (10,001 snapshots)  \n",
    "* **Labels:** PBE band‑gaps for each snapshot\n",
    "\n",
    "---\n",
    "\n",
    "## **Steps for Train/Validation/Test**\n",
    "\n",
    "###  Build the folder called **`root_dir/`**\n",
    "which contains all the POSCAR files of the AIMD trajectories\n",
    "\n",
    "```text\n",
    "st1.vasp, st2.vasp, st3.vasp, ..., st10001.vasp (10,000 POSCAR files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b861903c-2bdd-4dbe-b7d9-cb3df99b94f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "\n",
    "###  Create **`id_prop.csv`** of band‑gap labels with timestep 10 fs for train/validation/test\n",
    "\n",
    "```text\n",
    "structure_id,bandgap_eV\n",
    "st1,1.66\n",
    "st11,1.65\n",
    "st21,1.62\n",
    "    :\n",
    "st9999,1.77\n",
    "        (1001 rows)…\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42e343a-8d12-465e-a6a3-e95a0509d2b3",
   "metadata": {},
   "source": [
    "## **Train/validation/test strategy**  \n",
    "  * Only **10 %** of the 10 001 structures are used for model fitting  \n",
    "    (split **80 / 10 / 10** → train / val / test).  \n",
    "  * The remaining **90 %** of frames are later **predicted**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0997d8d-b3c7-4871-9544-3f7314254be6",
   "metadata": {},
   "source": [
    "### What the ensemble‑submission script does\n",
    "\n",
    "* **Why an ensemble?**  \n",
    "  * To cover the whole 10 ps with those 1001 dataset landscape we train **20 ALIGNN models**,  \n",
    "    each on a different **random shuffle of the id_prop.csv** files. Each run sees a different random 1 000‑frame sample\n",
    "(via shuffled id_prop.csv and a unique random_seed in config.json)\n",
    "\n",
    "* **What the script actually does for each run**  \n",
    "  1. Create `run_<n>/` inside `BASE_OUTPUT_DIR`.  \n",
    "  2. Copy `root_dir/` and a **shuffled** `id_prop.csv` (seed = unique).\n",
    "  3. Write `config.json` with that seed.  \n",
    "  4. Generate a one‑off `submit_job.sh` (Slurm, 1 GPU, 2 h).  \n",
    "  5. `sbatch` the job so logs & checkpoints stay in `run_<n>/`.\n",
    "\n",
    "  it would create folders like run_0, run_1, ..., run_19\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "deeb482f-1e9c-4777-aad9-8db7a8be4d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit_ensemble.py has been created.\n"
     ]
    }
   ],
   "source": [
    "# Cell [2]: Write out submit_ensemble.py\n",
    "script = r'''\n",
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "submit_ensemble.py\n",
    "\n",
    "This script automatically submits jobs for an ensemble of 20 ALIGNN training runs.\n",
    "For each run, it:\n",
    "\n",
    "* Creates a unique run folder (e.g., run_0, run_1, …, run_19) under a base output directory.\n",
    "* Copies the base config file (config_example.json) into that run folder and updates the \"random_seed\" field\n",
    "  with a unique random seed.\n",
    "* Copies the entire \"root_dir\" folder (from the current working directory) into the run folder.\n",
    "* Copies and shuffles the master id_prop.csv file (from the current directory) into the copied root_dir folder.\n",
    "* Writes a run-specific SBATCH job script that calls the training script with --root_dir set to the run-specific \"root_dir\".\n",
    "* Submits the job using sbatch so that outputs (e.g., slurm logs, checkpoints, and temp directories)\n",
    "  remain in the run folder.\n",
    "\n",
    "Please adjust the BASE_SOURCE_ROOT_DIR, BASE_CONFIG, BASE_OUTPUT_DIR, and other paths as needed.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import subprocess\n",
    "import time\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "# ----- Base directories and ensemble settings -----\n",
    "\n",
    "BASE_SOURCE_ROOT_DIR = os.path.join(os.getcwd(), \"root_dir\")\n",
    "BASE_ID_PROP         = os.path.join(os.getcwd(), \"id_prop.csv\")\n",
    "BASE_CONFIG          = \"/scratch/gilbreth/samantak/ALIGNN_AIMD_DFT_ML/Cl/train_to_10k/config_example.json\"\n",
    "BASE_OUTPUT_DIR      = \"/scratch/gilbreth/samantak/ALIGNN_AIMD_DFT_ML/Cl/train_to_10k\"\n",
    "ENSEMBLE_SIZE        = 20\n",
    "\n",
    "unique_seeds = random.sample(range(10000, 100000), ENSEMBLE_SIZE)\n",
    "\n",
    "def update_config(base_config_path, new_config_path, new_seed):\n",
    "    with open(base_config_path, \"r\") as f:\n",
    "        cfg = json.load(f)\n",
    "    cfg[\"random_seed\"] = new_seed\n",
    "    with open(new_config_path, \"w\") as f:\n",
    "        json.dump(cfg, f, indent=4)\n",
    "\n",
    "def copy_and_shuffle_idprop(source_csv, dest_csv, seed):\n",
    "    try:\n",
    "        df = pd.read_csv(source_csv)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {source_csv}: {e}\")\n",
    "        return False\n",
    "    df_shuffled = df.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "    df_shuffled.to_csv(dest_csv, index=False)\n",
    "    return True\n",
    "\n",
    "def write_job_script(job_script_path, run_dir, new_run_root_dir, config_path, run_index):\n",
    "    job_script = f\"\"\"#!/bin/bash\n",
    "#SBATCH -A standby\n",
    "#SBATCH -N 1\n",
    "#SBATCH --gpus=1\n",
    "#SBATCH -t 02:00:00\n",
    "#SBATCH --job-name cl10k_run_{run_index}\n",
    "#SBATCH -o {run_dir}/slurm-%j.out\n",
    "\n",
    "cd \"{run_dir}\"\n",
    "export PATH=/usr/local/cuda/bin:$PATH\n",
    "source ~/.bashrc\n",
    "conda_setup\n",
    "conda activate alignn_original\n",
    "\n",
    "train_alignn.py --root_dir \"{new_run_root_dir}\" --config \"{config_path}\" --output_dir \"./temp\"\n",
    "\"\"\"\n",
    "    with open(job_script_path, \"w\") as f:\n",
    "        f.write(job_script)\n",
    "    os.chmod(job_script_path, 0o755)\n",
    "\n",
    "def submit_job(job_script_path):\n",
    "    subprocess.run([\"sbatch\", job_script_path], check=True)\n",
    "\n",
    "def main():\n",
    "    for i in range(ENSEMBLE_SIZE):\n",
    "        run_dir = os.path.join(BASE_OUTPUT_DIR, f\"run_{i}\")\n",
    "        os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "        new_seed = unique_seeds[i]\n",
    "        new_config_path = os.path.join(run_dir, \"config.json\")\n",
    "        update_config(BASE_CONFIG, new_config_path, new_seed)\n",
    "\n",
    "        dest_root_dir = os.path.join(run_dir, \"root_dir\")\n",
    "        if os.path.exists(dest_root_dir):\n",
    "            shutil.rmtree(dest_root_dir)\n",
    "        shutil.copytree(BASE_SOURCE_ROOT_DIR, dest_root_dir)\n",
    "\n",
    "        dest_idprop = os.path.join(dest_root_dir, \"id_prop.csv\")\n",
    "        copy_and_shuffle_idprop(BASE_ID_PROP, dest_idprop, new_seed)\n",
    "\n",
    "        job_script_path = os.path.join(run_dir, \"submit_job.sh\")\n",
    "        write_job_script(job_script_path, run_dir, dest_root_dir, new_config_path, i)\n",
    "\n",
    "        try:\n",
    "            submit_job(job_script_path)\n",
    "            print(f\"Run {i}: submitted.\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Run {i} submission failed: {e}\")\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "# write to disk\n",
    "with open(\"submit_ensemble.py\", \"w\") as f:\n",
    "    f.write(script.strip())\n",
    "print(\"submit_ensemble.py has been created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f61b414-f091-4a45-a116-0e830b1be454",
   "metadata": {},
   "source": [
    "## 2. Run the submission script\n",
    "\n",
    "This will spin up all 20 jobs:\n",
    "\n",
    "```bash\n",
    "!chmod +x submit_ensemble.py\n",
    "!./submit_ensemble.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c899b62a-421e-44e0-8a55-f1bed0e2a6c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
